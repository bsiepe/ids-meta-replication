---
title: "Robustness replication of *A Bayesian Meta-Analysis of the Acoustic Properties of Infant-Directed Speech*"
author: 
 - name: Bj√∂rn S. Siepe
   orcid: 0000-0002-9558-4648
   affiliations: University of Marburg
 - name: Matthias Kloft
   orcid: 0000-0003-1845-6957
   affiliations: University of Marburg  
 - name: Semih Can Aktepe
   orcid: 0000-0002-4776-9138
   affiliations: University of Marburg
 - name: Daniel W. Heck
   orcid: 0000-0002-6302-9252
   affiliations: University of Marburg
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    number-sections: true
    theme: cosmo
    code-fold: true
    code-tools: true
    code-summary: "Show the code"
    fig-width: 7
    fig-height: 4.5
    fig-align: "center"
    embed-resoureces: true
execute:
  message: false
  warning: false
  eval: true
params: 
  refit: false
---

# Preparation
Load the necessary packages and set the seed for reproducibility.
```{r setup}
library(brms)
library(tidyverse)
library(here)
# library(renv)
library(tidybayes)
#library(RoBMA)
#library(osfr)
library(bayesplot)
#library(pander)
library(knitr)

set.seed(35032)
``` 


# Sampler Settings
The authors used relatively unorthodox sampler settings by choosing an `adapt_delta` of 0.99 and a `max_treedepth` of 20. We will compare fitting the models selected as best by the authors to the same models with more standard sampler settings, as this might give us an insight into potential issues with model complexity.

## F0
The authors selected the model with language, age, task & environment as predictors as the best model. 


We fit the model with typical settings on the first dataset to diagnose what is going wrong

```{r}
data_F0_multiple_final <- readRDS(here("data","data_F0_multiple_final.RData"))
```


```{r f0-sampler}
#| eval: !expr params$refit


baseline_te <- bf(Effect_Size | se(Effect_Size_se) ~ 1 + Age_months + 
                    Language + Environment + Task + (1 | Language/id_site/measurement_num))

priors1 <- c(brms::prior(normal(0, 2.5), class = Intercept),
             brms::prior(normal(1, 1), class = sd),
             brms::prior(normal(0, 1), class = b),
             brms::prior(normal(0, 0.05), class = b, coef = "Age_months"),
             brms::prior(gamma(2, 0.1), class = nu))

F0_task_environment_language_age_m_sampler <- 
  brm(
    baseline_te,
    save_pars = save_pars(all = TRUE),
    data = data_F0_multiple_final[[1]], 
    family = student,
    prior = priors1,
    iter = 1000, 
    warmup = 500,
    refresh = 1000,
    cores = 4,
    chains = 4
    )
saveRDS(F0_task_environment_language_age_m_sampler, here("output", "replication", "F0_task_environment_language_age_m_sampler.rds"))
```

```{r}
F0_task_environment_language_age_m_sampler <- 
  readRDS(here("output", "replication", "F0_task_environment_language_age_m_sampler.rds"))
```


```{r}
summary(F0_task_environment_language_age_m_sampler)
```

- Error variance is zero! We incorporate the residual in the model.

### Re-fit with residual variance
```{r }
#| eval: !expr params$refit

model_sigma_true <-  
  bf(Effect_Size | se(Effect_Size_se, sigma = TRUE) ~ 
       1 + Age_months + Language + Environment + Task + 
       (1 | Language/id_site/measurement_num))

priors1 <- c(brms::prior(normal(0, 2.5), class = Intercept),
             brms::prior(normal(1, 1), class = sd),
             brms::prior(normal(0, 1), class = b),
             brms::prior(normal(0, 0.05), class = b, coef = "Age_months"),
             brms::prior(gamma(2, 0.1), class = nu))

fit_sigma_true <- 
  brm(
    model_sigma_true,
    save_pars = save_pars(all = TRUE),
    data = data_F0_multiple_final[[1]], 
    family = student,
    prior = priors1,
    iter = 1000, 
    warmup = 500,
    refresh = 1000,
    cores = 4,
    chains = 4
    )
saveRDS(fit_sigma_true, here("output", "replication", "fit_sigma_true.rds"))
```

```{r}
fit_sigma_true <- readRDS(here("output", "replication", "fit_sigma_true.rds"))
```


```{r}
summary(fit_sigma_true)
```

Let's make the priors a little less informative

```{r }
#| eval: !expr params$refit


model_uninformative <-  
  bf(Effect_Size | se(Effect_Size_se, sigma = TRUE) ~ 
       1 + Age_months + Language + Environment + Task + 
       (1 | Language/id_site/measurement_num))

fit_uninformative <-
  brm(
    model_uninformative,
    save_pars = save_pars(all = TRUE),
    data = data_F0_multiple_final[[1]],
    family = student,
    iter = 1000,
    warmup = 500,
    refresh = 1000,
    cores = 4,
    chains = 4
  )

saveRDS(fit_uninformative, here("output", "replication", "fit_uninformative.rds"))
```

```{r}
fit_uninformative <- readRDS(here("output", "replication", "fit_uninformative.rds"))
```

```{r}
prior_summary(fit_uninformative)
```

```{r}
summary(fit_uninformative)
```

The model seems to be robust to the priors.
Let us build the model from simple to complex to see where the divergences occur 
first.

#### Intercept-only Model
```{r}
#| eval: !expr params$refit


model_step_0 <-  
  bf(Effect_Size | se(Effect_Size_se, sigma = TRUE) ~ 1)

fit_step_0 <- 
  brm(
    model_step_0,
    save_pars = save_pars(all = TRUE),
    data = data_F0_multiple_final[[1]], 
    family = student,
    iter = 1000, 
    warmup = 500,
    refresh = 1000,
    cores = 4,
    chains = 4
    )
saveRDS(fit_step_0, here("output", "replication", "fit_step_0.rds"))
```

```{r}
fit_step_0 <- readRDS(here("output", "replication", "fit_step_0.rds"))
```


```{r}
summary(fit_step_0)
```

Everything seems to be fine here. Let's add the random intercept for language.


#### Model: Intercept + Random Intercept for Language
```{r}
#| eval: !expr params$refit


model_step_1 <-  
  bf(Effect_Size | se(Effect_Size_se, sigma = TRUE) ~ 1 + (1 | Language))

fit_step_1 <- 
  brm(
    model_step_1,
    save_pars = save_pars(all = TRUE),
    data = data_F0_multiple_final[[1]], 
    family = student,
    iter = 1000, 
    warmup = 500,
    refresh = 1000,
    cores = 4,
    chains = 4
    )
saveRDS(fit_step_1, here("output", "replication", "fit_step_1.rds"))
```

```{r}
fit_step_1 <- readRDS(here("output", "replication", "fit_step_1.rds"))
```

```{r}
prior_summary(fit_step_1)
```


```{r}
summary(fit_step_1)
```

Everything seems to be fine here. Let's add the random intercept for site.

#### Model: Intercept + Random Intercept for Language + Random Intercept for Site
```{r}
#| eval: !expr params$refit


model_step_2 <-
  bf(Effect_Size | se(Effect_Size_se, sigma = TRUE) ~
       1 + (1 | Language / id_site))

fit_step_2 <-
  brm(
    model_step_2,
    save_pars = save_pars(all = TRUE),
    data = data_F0_multiple_final[[1]], 
    family = student,
    iter = 1000, 
    warmup = 500,
    refresh = 1000,
    cores = 4,
    chains = 4
    )
prior_summary(fit_step_2)
saveRDS(fit_step_2, here("output", "replication", "fit_step_2.rds"))
```

```{r}
fit_step_2 <- readRDS(here("output", "replication", "fit_step_2.rds"))
```


```{r}
summary(fit_step_2)
```

The nested random effects structure seems to be problematic. 

```{r}
bayesplot::mcmc_pairs(
  fit_step_2,
  np = nuts_params(fit_step_2),
  pars = c("Intercept", "sigma", "nu", "sd_Language__Intercept", "sd_Language:id_site__Intercept"),
  transform = list(),
off_diag_args = list(size = 0.7, alpha = 0.1))
```

#### Check Frequencies for Language and Site
```{r}
freq_language <- table(data_F0_multiple_final[[1]]$Language) %>% table()
freq_language
freq_language[1] / sum(freq_language)
freq_site <- table(data_F0_multiple_final[[1]]$id_site) %>% table()
freq_site
freq_site[1] / sum(freq_site)
```


#### Model: Intercept + Random Intercept for Language + Fixed Effects for Covariates
```{r}
model_step_3 <-  
  bf(Effect_Size | se(Effect_Size_se, sigma = TRUE) ~ 1 + 
       Age_months + Environment + Task +
       (1 | Language))

fit_step_3 <- 
  brm(
    model_step_3,
    save_pars = save_pars(all = TRUE),
    data = data_F0_multiple_final[[1]], 
    family = student,
    iter = 1000, 
    warmup = 500,
    refresh = 1000,
    cores = 4,
    chains = 4
    )
```

```{r}
print(summary(fit_step_3), digits = 3)
```

#### Fit again with multiple data sets

```{r}
#| eval: !expr params$refit

fit_step_3_multiple <- 
  brm_multiple(
    model_step_3,
    save_pars = save_pars(all = TRUE),
    data = data_F0_multiple_final, 
    family = student,
    iter = 1000, 
    warmup = 500,
    refresh = 1000,
    cores = 4,
    chains = 4
    )
saveRDS(fit_step_3_multiple, here("output", "replication", "fit_step_3_multiple.rds"))
```

```{r}
fit_step_3_multiple <- readRDS(here("output", "replication", "fit_step_3_multiple.rds"))
```

```{r}
print(summary(fit_step_3_multiple), digits = 3)
```









# Session Info

```{r}
pander::pander(sessionInfo())
```





